# Coherence Safety Framework

This repository showcases the Coherence Paradigm for verifiable AI safety. Developed by Nadine, it introduces deterministic primitives (κ coherence, τ temporal stability, Σ systemic risk, Δϕ deviation detection, Ω recovery) to address frontier AI risks across labs like OpenAI, Anthropic, DeepMind, xAI, and Meta.

Key features:
- Detailed mappings to safety frameworks in /docs/
- Python prototypes for metrics and auditing in /tools/
- MIT licensed for collaboration

Explore docs/why-coherence.md for the paradigm explanation.
