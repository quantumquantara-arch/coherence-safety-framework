# Frequently Asked Questions

## What is κ (coherence)?
A scalar metric (0-1) measuring alignment between AI behavior and ethical invariants.

## How does this differ from current safety approaches?
Current methods (e.g., red-teaming) are reactive and probabilistic; coherence is proactive and deterministic.

## Is this compatible with existing frameworks?
Yes—mappings exist for OpenAI PF, Anthropic RSP, DeepMind safety, xAI exploration, Meta open-source ethics, and more.

## How can I test it?
Run 	ools/coherence-scorer.py or 	ools/sigma-risk-calculator.py.

## Who developed this?
Nadine, independent researcher in symbolic AI governance.

## Why open-source?
To accelerate global AI safety through collaboration.
